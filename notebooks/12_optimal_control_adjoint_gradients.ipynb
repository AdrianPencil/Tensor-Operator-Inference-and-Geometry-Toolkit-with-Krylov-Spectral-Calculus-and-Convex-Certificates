{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85502622",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "  \"cells\": [\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"# 12 - Optimal control and adjoint gradients\\n\",\n",
    "        \"\\n\",\n",
    "        \"We define a small discrete-time linear system and verify gradients via autodiff.\\n\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"import tensorflow as tf\\n\",\n",
    "        \"from tig.core.random import Rng\\n\",\n",
    "        \"from tig.control.adjoint_methods import DiscreteDynamics, simulate_with_grad_u\\n\",\n",
    "        \"\\n\",\n",
    "        \"tf.keras.backend.set_floatx(\\\"float64\\\")\\n\",\n",
    "        \"tf.config.run_functions_eagerly(True)\\n\",\n",
    "        \"\\n\",\n",
    "        \"rng = Rng(seed=0)\\n\",\n",
    "        \"dt = 0.05\\n\",\n",
    "        \"n_steps = 30\\n\",\n",
    "        \"\\n\",\n",
    "        \"A = tf.eye(4, dtype=tf.float64) * tf.cast(0.95, tf.float64)\\n\",\n",
    "        \"B = rng.normal((4, 2), dtype=tf.float64) * tf.cast(0.1, tf.float64)\\n\",\n",
    "        \"x_target = rng.normal((4,), dtype=tf.float64)\\n\",\n",
    "        \"\\n\",\n",
    "        \"def f(x: tf.Tensor, u: tf.Tensor, t: float) -> tf.Tensor:\\n\",\n",
    "        \"    return (A @ tf.reshape(x, (-1, 1)))[:, 0] + (B @ tf.reshape(u, (-1, 1)))[:, 0]\\n\",\n",
    "        \"\\n\",\n",
    "        \"dyn = DiscreteDynamics(f=f)\\n\",\n",
    "        \"x0 = rng.normal((4,), dtype=tf.float64)\\n\",\n",
    "        \"u0 = rng.normal((n_steps, 2), dtype=tf.float64)\\n\",\n",
    "        \"\\n\",\n",
    "        \"def loss(traj: tf.Tensor, u: tf.Tensor) -> tf.Tensor:\\n\",\n",
    "        \"    e = traj[-1] - x_target\\n\",\n",
    "        \"    return tf.reduce_sum(e * e) + tf.cast(1e-3, tf.float64) * tf.reduce_sum(u * u)\\n\",\n",
    "        \"\\n\",\n",
    "        \"L, g = simulate_with_grad_u(dyn=dyn, x0=x0, u0=u0, t0=0.0, dt=dt, loss=loss)\\n\",\n",
    "        \"print(\\\"loss:\\\", float(tf.reshape(L, ()).numpy()))\\n\",\n",
    "        \"print(\\\"||grad||:\\\", float(tf.linalg.norm(tf.reshape(g, (-1,))).numpy()))\\n\"\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  \"metadata\": {\n",
    "    \"kernelspec\": {\n",
    "      \"display_name\": \"Python 3\",\n",
    "      \"language\": \"python\",\n",
    "      \"name\": \"python3\"\n",
    "    },\n",
    "    \"language_info\": {\n",
    "      \"name\": \"python\",\n",
    "      \"version\": \"3.x\"\n",
    "    }\n",
    "  },\n",
    "  \"nbformat\": 4,\n",
    "  \"nbformat_minor\": 5\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
